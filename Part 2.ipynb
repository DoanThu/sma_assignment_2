{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part II no. 1\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# get all txt filenames in a folder\n",
    "doc_files = glob.glob(r'D:\\Programming Exercise 2\\resources\\documents\\*.txt')\n",
    "#print(doc_files[:7])\n",
    "        \n",
    "def sort_key(s):\n",
    "    size=len(s)\n",
    "    size=-size\n",
    "    num=0\n",
    "    #print(s)\n",
    "    for i in range(-5, size,-1):\n",
    "        try:\n",
    "            num=int(s[i])\n",
    "            #print(num)\n",
    "        except:\n",
    "            #print(s[i+1:-4])\n",
    "            return int(os.path.basename(s)[i+1:-4])\n",
    "\n",
    "doc_files.sort(key=sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "(2500, 5032)\n"
     ]
    }
   ],
   "source": [
    "# method to read all lines in a document and return it as a string\n",
    "def read_all_lines(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.read().replace('\\n', '')\n",
    "        #lines = f.read()\n",
    "    return lines\n",
    "\n",
    "# build doc corpus\n",
    "doc_corpus = []\n",
    "for fileName in doc_files:\n",
    "    text = read_all_lines(fileName)\n",
    "    doc_corpus.append(text)\n",
    "\n",
    "print(len(doc_corpus))\n",
    "# create vector space representations using standard TF-IDF weighting scheme\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_doc = vectorizer.fit_transform(doc_corpus)\n",
    "# print(vectorizer.get_feature_names())\n",
    "print(X_doc.shape)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5032)\n"
     ]
    }
   ],
   "source": [
    "# Part II no. 2\n",
    "# get all txt filenames in a folder\n",
    "query_files = sorted(glob.glob(r'D:\\Programming Exercise 2\\resources\\queries\\*.txt'))\n",
    "\n",
    "query_files.sort(key=sort_key)\n",
    "\n",
    "# build query corpus\n",
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english')\n",
    "query_corpus = []\n",
    "\n",
    "for fileName in query_files:\n",
    "    text = read_all_lines(fileName)\n",
    "    clean_word_list = [word for word in text.split() if word not in stoplist] \n",
    "    text = \" \" \n",
    "    text = text.join(clean_word_list)\n",
    "    query_corpus.append(text)\n",
    "\n",
    "X_query = vectorizer.transform(query_corpus)\n",
    "# print(vectorizer.get_feature_names())\n",
    "print(X_query.shape)\n",
    "# print(X_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "query_num,doc_num=X_query.shape[0],X_doc.shape[0]\n",
    "cos_dis=np.zeros((query_num,doc_num))\n",
    "\n",
    "for i in range(query_num):\n",
    "    for j in range(doc_num):\n",
    "        cos_dis[i][j]=cosine_similarity(X_query[i],X_doc[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=np.zeros((query_num, 10))\n",
    "\n",
    "for i in range(query_num):\n",
    "    candidates=cos_dis[i]\n",
    "    cur_res=candidates.argsort()[::-1][:10]\n",
    "    res[i]=cur_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1137. 1497. 2324. 2387.  354.  362.  334.  342.  718. 1473.]\n",
      " [1226.  795. 1682. 1687. 1042. 1197. 1196.  542. 1689. 1680.]\n",
      " [ 986. 2195.  351.  350.  324.  983.  326.  331.  156.  128.]]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
